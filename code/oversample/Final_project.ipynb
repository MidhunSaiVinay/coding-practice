{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc717308-7c03-4fe3-b3b9-5bec35e7bf85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Cell 1: suppress warnings & import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, multilabel_confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a290a-9c75-4ffe-8d62-dcae0203dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: load your features & labels\n",
    "# assumes train/<val>_features_no_dmg_resnet.csv live in same folder as this notebook\n",
    "train_df = pd.read_csv('train_features_no_dmg_resnet.csv')\n",
    "val_df   = pd.read_csv('val_features_no_dmg_resnet.csv')\n",
    "\n",
    "print(f\"Training set: {train_df.shape}, Validation set: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daac57-bc64-407e-b2bf-e53c600d2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: define feature matrix X and label vector y\n",
    "label_col = 'damage_type'   # ‚Üê replace with your actual target column name\n",
    "\n",
    "X_train = train_df.drop(columns=[label_col]).values\n",
    "y_train = train_df[label_col].values\n",
    "\n",
    "X_val   = val_df.drop(columns=[label_col]).values\n",
    "y_val   = val_df[label_col].values\n",
    "\n",
    "# encode labels to integers\n",
    "le      = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val   = le.transform(y_val)\n",
    "\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fa1ee-73f9-4c18-be6d-e81da7ed6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = y_train.sum().sort_values(ascending=False)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab589d-a999-402f-bf48-39899562db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title(\"Label Distribution in y_train\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565063b4-933e-4f78-b37d-1ed02592ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: handle multiclass imbalance\n",
    "# Option A: simple RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Option B (alternative): SMOTE for multiclass\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before resampling:\", np.bincount(y_train))\n",
    "print(\"After  resampling:\", np.bincount(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bab3c-9cee-4b2a-a296-cbbc3559fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: train & evaluate Logistic Regression\n",
    "lr = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
    "lr.fit(X_res, y_res)\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "print(\"Logistic Regression Metrics\")\n",
    "print(\"Confusion matrices:\\n\", multilabel_confusion_matrix(y_val, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "print(\"F1 (micro):\", f1_score(y_val, y_pred_lr, average='micro'))\n",
    "print(\"Precision (micro):\", precision_score(y_val, y_pred_lr, average='micro'))\n",
    "print(\"Recall (micro):\", recall_score(y_val, y_pred_lr, average='micro', zero_division=0))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred_lr, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2a6e1-c7a5-44f5-b3a1-7d3568d059ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: train & evaluate MLPClassifier\n",
    "mlp = OneVsRestClassifier(MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42))\n",
    "mlp.fit(X_res, y_res)\n",
    "y_pred_mlp = mlp.predict(X_val)\n",
    "\n",
    "print(\"MLP Classifier Metrics\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_mlp))\n",
    "print(\"F1 (micro):\", f1_score(y_val, y_pred_mlp, average='micro'))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_mlp, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205f2d1-abe6-49c8-a305-ef33805e629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf=OneVsRestClassifier(LogisticRegression(penalty='l2',solver='newton-cg', \n",
    "                      max_iter=1500))\n",
    "\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_val)\n",
    "\n",
    "confM = multilabel_confusion_matrix(y_val, y_pred)\n",
    "print(confM)\n",
    "\n",
    "acc=accuracy_score(y_val, y_pred)\n",
    "F1=f1_score(y_val, y_pred,average='micro')\n",
    "precicion = precision_score(y_val, y_pred, average='micro')\n",
    "recall = recall_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "print('By hold-out evaluation: acc = ',acc, ',F1 = ',F1, 'precicion =  ' ,precicion , 'recall = ' , recall )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e88679-d216-40b8-bd91-56eaea1d3376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e798555-8a1e-45bc-81e6-7a87a002021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    multilabel_confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# === Data Splitting ===\n",
    "X_train = train_df.iloc[:, :2047]\n",
    "y_train = train_df.iloc[:, 2048:]\n",
    "X_val = val_df.iloc[:, :2047]\n",
    "y_val = val_df.iloc[:, 2048:]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "# === Grid Search Setup ===\n",
    "base_clf = LogisticRegression(solver='saga', max_iter=5000)\n",
    "ovr = OneVsRestClassifier(base_clf)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'estimator__penalty': ['l1', 'l2'],\n",
    "    'estimator__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ovr,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_micro',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Model Training ===\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# === Evaluation ===\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "confM = multilabel_confusion_matrix(y_val, y_pred)\n",
    "print(confM)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "F1 = f1_score(y_val, y_pred, average='micro')\n",
    "precicion = precision_score(y_val, y_pred, average='micro')\n",
    "recall = recall_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "\n",
    "print('By hold-out evaluation: acc = ', acc, ',F1 = ', F1, \n",
    "      'precicion = ', precicion, 'recall = ', recall)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986654c-2be7-42c3-a8c4-f9f50759b1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a364c69-00a0-4829-a46d-ccad21afe60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "bag = RandomForestClassifier(n_estimators=100, max_samples=0.8, random_state=1)\n",
    "\n",
    "clf=bag.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_val)\n",
    "\n",
    "confM = multilabel_confusion_matrix(y_val, y_pred)\n",
    "print(confM)\n",
    "\n",
    "acc=accuracy_score(y_val, y_pred)\n",
    "F1=f1_score(y_val, y_pred,average='micro')\n",
    "precicion = precision_score(y_val, y_pred, average='micro')\n",
    "recall = recall_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "print('By hold-out evaluation: acc = ',acc, ',F1 = ',F1, 'precicion =  ' ,precicion , 'recall = ' , recall )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8c9a9-e2b6-41d0-b4f4-a6eed41f7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLPCLASSIFIER\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = OneVsRestClassifier(MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50), activation='relu',solver='adam',alpha=0.0001, batch_size='auto',learning_rate='adaptive',max_iter=200,random_state=1))\n",
    "clf=mlp.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_val)\n",
    "\n",
    "confM = multilabel_confusion_matrix(y_val, y_pred)\n",
    "print(confM)\n",
    "\n",
    "acc=accuracy_score(y_val, y_pred)\n",
    "F1=f1_score(y_val, y_pred,average='micro')\n",
    "precicion = precision_score(y_val, y_pred, average='micro')\n",
    "recall = recall_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "print('By hold-out evaluation: acc = ',acc, ',F1 = ',F1, 'precicion =  ' ,precicion , 'recall = ' , recall )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a215db5-009d-411a-afcc-5d2fd6252614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = OneVsRestClassifier(XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    scale_pos_weight=1, \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=1000\n",
    "))\n",
    "\n",
    "clf=xgb.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_val)\n",
    "\n",
    "confM = multilabel_confusion_matrix(y_val, y_pred)\n",
    "print(confM)\n",
    "\n",
    "acc=accuracy_score(y_val, y_pred)\n",
    "F1=f1_score(y_val, y_pred,average='micro')\n",
    "precicion = precision_score(y_val, y_pred, average='micro')\n",
    "recall = recall_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "print('By hold-out evaluation: acc = ',acc, ',F1 = ',F1, 'precicion =  ' ,precicion , 'recall = ' , recall )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3010fcc-f9d2-45cc-a72f-1fddea154419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
